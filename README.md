# ğŸ“Š Model Training Report

![License](https://img.shields.io/badge/License-MIT-blue.svg)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-1.8.1-brightgreen.svg)

## ğŸš€ Project Overview

**CIFAR-10 ë¶„ë¥˜ë¥¼ ìœ„í•œ ResNet**
`PyTorch`ë¥¼ ì‚¬ìš©í•˜ì—¬ `Residual Network`(`ResNet`) ì•„í‚¤í…ì²˜ë¥¼ êµ¬í˜„í•œ ê²ƒìœ¼ë¡œ, `CIFAR-10` ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì— íŠ¹í™”. ResNetì˜ `Skip connection`ì€ ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œë¥¼ ì™„í™”í•˜ì—¬ ë§¤ìš° ê¹Šì€ ì‹ ê²½ë§ì˜ íš¨ê³¼ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, ë‹¤ì–‘í•œ ì»´í“¨í„° ë¹„ì „ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜.

## ğŸ“‹ Training Details

- **Framework**: PyTorch
- **Optimizer**: Adam
- **Loss Function**: CrossEntropyLoss
- **Learning Rate**: 0.001
- **Epochs**: 20
- **Batch Size (Training)**: 64
- **Batch Size (Validation & Evaluation)**: 100
- **Metrics**: Accuracy, Loss
- **Data Split**: Training and validation sets


## ğŸ” Feature

- **ê¹Šì€ Residual Network**: ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥í•œ ê¹Šì´ë¥¼ ê°€ì§„ `ResNet` êµ¬í˜„
- **ë°ì´í„° ì¦ê°•**: ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì¼ë°˜ì ì¸ ë°ì´í„° ì¦ê°• ê¸°ë²• í™œìš©
- **í•™ìŠµ ë° í‰ê°€ ìŠ¤í¬ë¦½íŠ¸**: ëª¨ë¸ í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ìŠ¤í¬ë¦½íŠ¸ ì œê³µ
- **ì‹œê°í™” ë„êµ¬**: í•™ìŠµ ì§„í–‰ ìƒí™©ê³¼ ëª¨ë¸ ì„±ëŠ¥ì„ ì‹œê°í™”í•˜ëŠ” ë„êµ¬
- **ëª¨ë“ˆí™”ëœ ì½”ë“œë² ì´ìŠ¤**: ì´í•´ì™€ í™•ì¥ì´ ìš©ì´í•œ ê¹”ë”í•˜ê³  ëª¨ë“ˆí™”ëœ ì½”ë“œ êµ¬ì¡°

## ğŸ” Model architecture

ëª¨ë¸ì€ `PyTorch`ì˜ `nn.Module`ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì„± ìš”ì†Œë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤:

- **ì´ˆê¸° Convolutional Layer**: 3x3 Convolutionìœ¼ë¡œ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬
- **Residual Blocks**: Skip connectionì„ í†µí•œ Residual Blocksì˜ ë‹¤ì¤‘ ìŒ“ê¸°
- **Adaptive Average Pooling**: Fully Connected Layer ì „ì— ê³µê°„ì  ì°¨ì›ì„ ì¶•ì†Œ
- **Fully Connected Layer**: CIFAR-10 ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ í™•ë¥ ì„ ì¶œë ¥

### Residual Block

ê° Residual Blockì€ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì„± ìš”ì†Œë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤:

1. **Convolutional Layer**: `Batch Normalization`ê³¼ `ReLU` í™œì„±í™” í•¨ìˆ˜ë¥¼ í¬í•¨í•œ 3x3 Convolution
2. **ë‘ ë²ˆì§¸ Convolutional Layer**: `Batch Normalization`ì„ í¬í•¨í•œ ë˜ ë‹¤ë¥¸ 3x3 Convolution
3. **Skip Connection**: ì…ë ¥ì„ ë‘ ë²ˆì§¸ Convolutional Layerì˜ ì¶œë ¥ì— ë”í•¨
4. **ìµœì¢… ReLU í™œì„±í™” í•¨ìˆ˜**: ê²°í•©ëœ ì¶œë ¥ì— `ReLU` í™œì„±í™” ì ìš©

![ResNet Architecture](https://i.imgur.com/3cU8gfk.png)
*Residual Blockì˜ ì˜ˆì‹œ*

## ğŸ” Install

ğŸ“‚ Repository Structure

```bash
â”œâ”€â”€ data/              # Dataset
â”œâ”€â”€ outputs/           # Training logs and visualizations
â”œâ”€â”€ train.py           # Training script
â”œâ”€â”€ requirements.txt   # Dependencies
â””â”€â”€ README.md          # Project 
```

### Requirements

- `Python 3.8` ì´ìƒ
- `PyTorch 1.8.1` ì´ìƒ
- ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” `requirements.txt` ì°¸ê³ 

```bash
pip install -r requirements.txt
```

### Repository Clone

```bash
git clone https://github.com/yourusername/resnet-cifar10.git
```

## ğŸ“ˆ Result

### Training Metrics

| Epoch | Train Loss | Train Accuracy | Validation Loss | Validation Accuracy |
|-------|------------|----------------|-----------------|---------------------|
| 1     | 1.4865     | 45.08%         | 1.2336          | 55.66%              |
| 2     | 1.1026     | 60.48%         | 1.1540          | 59.80%              |
| 3     | 0.9440     | 66.63%         | 0.8909          | 68.12%              |
| 4     | 0.8450     | 70.04%         | 0.9167          | 67.14%              |
| 5     | 0.7727     | 72.80%         | 0.8419          | 70.76%              |
| 6     | 0.7122     | 75.22%         | 0.7663          | 73.14%              |
| 7     | 0.6606     | 77.27%         | 0.7838          | 73.62%              |
| 8     | 0.6179     | 78.62%         | 0.7182          | 75.22%              |
| 9     | 0.5861     | 79.75%         | 0.6205          | 77.74%              |
| 10    | 0.5580     | 80.79%         | 0.6947          | 76.28%              |
| 11    | 0.5372     | 81.28%         | 0.6353          | 78.42%              |
| 12    | 0.5135     | 82.15%         | 0.6126          | 78.46%              |
| 13    | 0.4940     | 82.94%         | 0.5304          | 81.82%              |
| 14    | 0.4748     | 83.67%         | 0.6967          | 76.88%              |
| 15    | 0.4587     | 84.16%         | 0.5281          | 81.82%              |
| 16    | 0.4403     | 84.74%         | 0.5243          | 82.34%              |
| 17    | 0.4313     | 85.08%         | 0.5156          | 82.48%              |
| 18    | 0.4177     | 85.50%         | 0.5191          | 82.62%              |
| 19    | 0.4081     | 85.80%         | 0.4975          | 83.22%              |
| 20    | 0.3969     | 86.34%         | 0.4911          | 83.92%              |


![alt text](image.png)
*Training VS Validation*

### Accuracy and Loss Trends
**Training Accuracy**:	ì§€ì†ì ì¸ í–¥ìƒì„ ë³´ì´ë©° ìµœì¢… ì—í¬í¬ì—ì„œ 86.34%ì— ë„ë‹¬	86.34%
**Validation Accuracy**:	ìœ ì‚¬í•œ ì¶”ì„¸ë¥¼ ë³´ì´ë©° 83.92%ë¡œ ì•ˆì •í™”, ì¢‹ì€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒ„	83.

**Training Loss**:	ì§€ì†ì ì¸ ê°ì†Œë¥¼ ë³´ì´ë©° ìµœì¢… ì—í¬í¬ì—ì„œ 0.3969ì— ë„ë‹¬	0.3969
**Validation Loss**:	ìœ ì‚¬í•œ ê°ì†Œ ì¶”ì„¸ë¥¼ ë³´ì´ë©° 0.4911ë¡œ ë§ˆë¬´ë¦¬, íš¨ê³¼ì ì¸ í•™ìŠµì„ ë‚˜íƒ€ëƒ„	0.4911

**ì„±ëŠ¥ í–¥ìƒ**:	Training Accuracyê°€ 45.08%ì—ì„œ 86.34%ë¡œ ì¦ê°€, Validation Accuracyê°€ 55.66%ì—ì„œ 83.92%ë¡œ í–¥ìƒë¨
**ì¼ê´€ëœ í•™ìŠµ ê³¼ì •**:	ëª¨ë“  ì—í¬í¬ì—ì„œ ì†ì‹¤ ê°ì†Œ, ì •í™•ë„ ì¦ê°€ ì¶”ì„¸ë¥¼ ë³´ì„
**ê³¼ì í•© ë°©ì§€**:	Validation Accuracyê°€ Training Accuracyì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ë” ë†’ì•„ ê³¼ì í•© ì—†ìŒ

### Things to improve
**í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**:	í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ì—í¬í¬ ìˆ˜ ë“±ì„ ì¶”ê°€ë¡œ ì¡°ì •í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥
**ë°ì´í„° ì¦ê°•(Data Augmentation)**:	ë°ì´í„° ì¦ê°• ê¸°ë²• ë„ì…ìœ¼ë¡œ ëª¨ë¸ì˜ ì¼ë°˜í™” ê°•í™”
**ë” ê¹Šì€ ëª¨ë¸ íƒìƒ‰**:	í˜„ì¬ë³´ë‹¤ ë” ê¹Šê±°ë‚˜ ë³µì¡í•œ ëª¨ë¸ì„ ì‹¤í—˜í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ ë„ëª¨